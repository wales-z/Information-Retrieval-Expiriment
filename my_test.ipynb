{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Import libraries or packges that we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\r\n",
    "from torch.utils.data import Dataset, DataLoader\r\n",
    "import torch.nn as nn\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.metrics import mean_squared_error\r\n",
    "from model import mf, mfDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Set the training configuration, i.e. hyper-paramters, computing device, dataset path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../data/1m.dat'\r\n",
    "batch_size = 2048\r\n",
    "device = torch.device('cuda:0')\r\n",
    "learning_rate = 1e-4\r\n",
    "weight_decay = 3e-5\r\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Preprocessing before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_movies: 3883\n",
      "num_users: 6040\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(file_path, header=None, delimiter='::')\r\n",
    "x, y = df.iloc[:, :2], df.iloc[:, 2]\r\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1)\r\n",
    "\r\n",
    "train_dataset = mfDataset(np.array(x_train[0]), np.array(\r\n",
    "        x_train[1]),  np.array(y_train).astype(np.float32))\r\n",
    "test_dataset = mfDataset(np.array(x_test[0]), np.array(\r\n",
    "        x_test[1]), np.array(y_test).astype(np.float32))\r\n",
    "\r\n",
    "train_DataLoader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\r\n",
    "test_DataLoader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\r\n",
    "\r\n",
    "mean_rating = df.iloc[:, 2].mean()\r\n",
    "num_users = max(df[0])+1\r\n",
    "num_items = max(df[1])+1\r\n",
    "print(f\"num_users:{num_users}\")\r\n",
    "print(f\"num_items:{num_items}\")\r\n",
    "\r\n",
    "model = mf(num_users, num_items, mean_rating).to(device)\r\n",
    "model_my_SGD=mf(num_users, num_items, mean_rating).to(device)\r\n",
    "\r\n",
    "optimizer = torch.optim.SGD(\r\n",
    "        params=model.parameters(), lr=learning_rate)\r\n",
    "\r\n",
    "# optimizer = torch.optim.Adam(``\r\n",
    "#         params=model.parameters(), lr=learning_rate, weight_decay=weight_decay)\r\n",
    "\r\n",
    "loss_func = torch.nn.MSELoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Training and evaluation\r\n",
    "optimization method: Stochastic Gradient Descent (SGD) or Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\r\n",
    "    # training phase\r\n",
    "    model.train()\r\n",
    "    total_loss, total_len = 0, 0\r\n",
    "    for x_u, x_i, y in train_DataLoader:\r\n",
    "        x_u, x_i, y = x_u.to(device), x_i.to(device), y.to(device)\r\n",
    "        y_pre = model(x_u, x_i)\r\n",
    "        loss = loss_func(y_pre, y)\r\n",
    "\r\n",
    "        # auto gradient computing and gradient descent based on pytorch\r\n",
    "        optimizer.zero_grad()\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "\r\n",
    "        total_loss += loss.item()*len(y)\r\n",
    "        total_len += len(y)\r\n",
    "    train_loss = total_loss/total_len\r\n",
    "\r\n",
    "    # evaluation phase\r\n",
    "    model.eval()\r\n",
    "    labels, predicts = [], []\r\n",
    "    with torch.no_grad():\r\n",
    "        for x_u, x_i, y in test_DataLoader:\r\n",
    "            x_u, x_i, y = x_u.to(device), x_i.to(device), y.to(device)\r\n",
    "            y_pre = model(x_u, x_i)\r\n",
    "            labels.extend(y.tolist())\r\n",
    "            predicts.extend(y_pre.tolist())\r\n",
    "    mse = mean_squared_error(np.array(labels), np.array(predicts))\r\n",
    "\r\n",
    "    print(\"epoch {}, train loss is {}, val mse is {}\".format(\r\n",
    "        epoch, train_loss, mse))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "name": "python376jvsc74a57bd051a9663a131f1b5758c45b97a2d6917c8ae86b33e231c3733631cbc7265cfc89"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}